{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from functools import reduce\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from xgboost import XGBClassifier, XGBRegressor, plot_importance\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_dotenv(\"\")\n",
    "FREDkey = os.getenv(\"FREDkey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist = [\"WILL5000INDFC\",\n",
    "           \"NIKKEI225\",\n",
    "           \"CPIAUCSL\",\n",
    "           \"CPIFABSL\",\n",
    "           \"CPIHOSSL\",\n",
    "           \"IC4WSA\",\n",
    "           \"INDPRO\",\n",
    "           \"IPMAN\",\n",
    "           \"HOUST\",\n",
    "           \"HSN1F\",\n",
    "           \"RELACBW027SBOG\",\n",
    "           \"MSPNHSUS\",\n",
    "           \"USSTHPI\",\n",
    "           \"AHETPI\",\n",
    "           \"PCE\",\n",
    "           \"PCEND\",\n",
    "           \"DAUTOSAAR\",\n",
    "           \"PI\",\n",
    "           \"A229RX0\",\n",
    "           \"DEXJPUS\",\n",
    "           \"DTWEXM\",\n",
    "           \"DGS30\",\n",
    "           \"DGS10\",\n",
    "           \"DGS2\",\n",
    "           \"DGS5\",\n",
    "           \"DTB3\",\n",
    "           \"MORTGAGE30US\",\n",
    "           \"AAA\",\n",
    "           \"BAA\",\n",
    "           \"BAMLCC0A0CMTRIV\",\n",
    "           \"FEDFUNDS\",\n",
    "           \"TB3SMFFM\",\n",
    "           \"UMCSENT\",  \n",
    "           \"CIVPART\",\n",
    "           \"TCU\",\n",
    "           \"UNRATE\",\n",
    "           \"LNS14000002\",\n",
    "           \"LNS15000000\",\n",
    "           \"UEMPMEAN\",\n",
    "           \"USCONS\",\n",
    "           \"NFCI\",\n",
    "           \"USRECDM\",\n",
    "           \"GDPPOT\",\n",
    "           \"GDPC1\",\n",
    "           \"GOLDPMGBD228NLBM\",\n",
    "           \"WTISPLC\",\n",
    "           \"CMRMTSPL\",\n",
    "           \"TERMCBAUTO48NS\",\n",
    "           \"TERMCBPER24NS\",\n",
    "           \"NONREVSL\",\n",
    "           \"CEFDFSA066MSFRBPHI\",\n",
    "           \"M1SL\",\n",
    "           \"MABMM301USM189S\",\n",
    "           \"TOTALSA\",\n",
    "           \"INTDSRUSM193N\",\n",
    "           \"PSAVERT\",\n",
    "           \"TOTCI\",\n",
    "           \"TOTLL\",\n",
    "           \"TOTBKCR\",\n",
    "           \"DPRIME\",\n",
    "           \"MSACSR\",\n",
    "           \"PPIACO\",\n",
    "           \"PERMIT\",\n",
    "           \"DSPIC96\",\n",
    "           \"TLAACBW027SBOG\",\n",
    "           \"M12MTVUSM227NFWA\",\n",
    "           \"AWHMAN\",\n",
    "           \"CCSA\",\n",
    "           \"TCD\",\n",
    "           \"CSCICP03USM665S\"\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datalist=[]\n",
    "for var in varlist:\n",
    "    resp = requests.get(\n",
    "        \"https://api.stlouisfed.org/fred/series/observations?series_id={}&api_key={}&file_type=json\"\n",
    "        .format(var, \n",
    "                FREDkey))\n",
    "    df = pd.DataFrame(resp.json()['observations'])\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.loc[df.value!=\".\"]\n",
    "    df.value = df.value.astype(float)\n",
    "    df.index = df.date\n",
    "    df.drop(columns=[\"realtime_end\", \"realtime_start\", \"date\"], axis=1, inplace=True)\n",
    "    df.columns=[var]\n",
    "    df= df.resample(\"1D\").interpolate(method='linear')\n",
    "    datalist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = reduce(lambda left, right: pd.merge(left, right, on='date', how='outer'), datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63858, 70)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"2-10\"] = df_merged.DGS10 - df_merged.DGS2\n",
    "df_merged[\"10-30\"] = df_merged.DGS30 - df_merged.DGS10\n",
    "df_merged[\"positive_gap\"] = df_merged.GDPC1.pct_change(365) - df_merged.GDPPOT.pct_change(365) > 0\n",
    "df_merged[\"gap\"] = df_merged.GDPC1.pct_change(365) - df_merged.GDPPOT.pct_change(365)\n",
    "df_WILL5000_5d_vol = df_merged.WILL5000INDFC.pct_change(1).rolling(5).std()\n",
    "df_WILL5000_30d_vol = df_merged.WILL5000INDFC.pct_change(1).rolling(30).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_WILL5000_5d_vol= df_WILL5000_5d_vol.loc[df_merged.DGS30>-10].resample(\"1W\").mean()\n",
    "df_WILL5000_30d_vol= df_WILL5000_30d_vol.loc[df_merged.DGS30>-10].resample(\"1W\").mean()\n",
    "df_merged = df_merged.loc[df_merged.DGS30>-10].resample(\"1W\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = [\"WILL5000INDFC\",\n",
    "           \"NIKKEI225\",\n",
    "           \"CPIAUCSL\", \n",
    "           \"CPIFABSL\",\n",
    "           \"CPIHOSSL\",\n",
    "           \"IC4WSA\",\n",
    "           \"INDPRO\",\n",
    "           \"IPMAN\",\n",
    "           \"HOUST\",\n",
    "           \"HSN1F\",\n",
    "           \"RELACBW027SBOG\",\n",
    "           \"MSPNHSUS\",\n",
    "           \"USSTHPI\",\n",
    "           \"AHETPI\",\n",
    "           \"PCE\",\n",
    "           \"PCEND\",\n",
    "           \"DAUTOSAAR\",\n",
    "           \"A229RX0\",\n",
    "           \"DEXJPUS\",\n",
    "           \"DTWEXM\",\n",
    "           \"GOLDPMGBD228NLBM\",\n",
    "           \"WTISPLC\",\n",
    "           \"BAMLCC0A0CMTRIV\",\n",
    "           \"CMRMTSPL\",\n",
    "           \"NONREVSL\",\n",
    "           \"M1SL\",\n",
    "           \"MABMM301USM189S\",\n",
    "           \"TOTALSA\",\n",
    "           \"TOTCI\",\n",
    "           \"TOTLL\",\n",
    "           \"TOTBKCR\",\n",
    "           \"PPIACO\",\n",
    "           \"PERMIT\",\n",
    "           \"DSPIC96\",\n",
    "           \"TLAACBW027SBOG\",\n",
    "           \"M12MTVUSM227NFWA\",\n",
    "           \"PI\",\n",
    "           \"AWHMAN\",\n",
    "           \"CCSA\",\n",
    "           \"TCD\",\n",
    "           \"UEMPMEAN\",\n",
    "           \"LNS15000000\",\n",
    "           \"USCONS\"\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [\"DGS30\",\n",
    "          \"DGS10\",\n",
    "          \"DGS2\",\n",
    "          \"DGS5\",\n",
    "          \"DTB3\",\n",
    "          \"MORTGAGE30US\",\n",
    "          \"AAA\",\n",
    "          \"BAA\",\n",
    "          \"FEDFUNDS\",\n",
    "          \"TB3SMFFM\",\n",
    "          \"UMCSENT\",  \n",
    "          \"CIVPART\",\n",
    "          \"TCU\",\n",
    "          \"UNRATE\",\n",
    "          \"LNS14000002\",\n",
    "          \"NFCI\",\n",
    "          \"2-10\",\n",
    "          \"10-30\",\n",
    "          \"gap\",\n",
    "          \"TERMCBAUTO48NS\",\n",
    "          \"TERMCBPER24NS\",\n",
    "          \"CEFDFSA066MSFRBPHI\",\n",
    "          \"INTDSRUSM193N\",\n",
    "          \"PSAVERT\",\n",
    "          \"DPRIME\",\n",
    "          \"MSACSR\",\n",
    "          \"CSCICP03USM665S\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(df, percent, actual, period):\n",
    "    df_actual = df[actual].diff(period).fillna(method='ffill')\n",
    "\n",
    "    df_percent = df[percent].pct_change(period).fillna(method='ffill')\n",
    "    df_concat = pd.concat([df_actual, df_percent], axis=1)\n",
    "    df_concat.columns = [str(col) + '_{}'.format(period) for col in df_concat.columns]\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "week = change(df_merged, percent, actual, 1)\n",
    "week_week = week.diff(1).add_suffix(\"_1\")\n",
    "month = change(df_merged, percent, actual, 4)\n",
    "month_month = month.diff(4).add_suffix(\"_4\")\n",
    "three_m = change(df_merged, percent, actual, 13)\n",
    "three_three = three_m.diff(13).add_suffix(\"_13\")\n",
    "six_m = change(df_merged, percent, actual, 26)\n",
    "six_six = six_m.diff(26).add_suffix(\"_26\")\n",
    "one_y = change(df_merged, percent, actual, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([week, \n",
    "               week_week, \n",
    "               month, \n",
    "               month_month, \n",
    "               three_m, \n",
    "               three_three, \n",
    "               six_m, \n",
    "               six_six, \n",
    "               one_y,\n",
    "               df_merged[actual].fillna(method=\"ffill\"),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(1),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(4),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(13),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(26),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(52),\n",
    "               df_WILL5000_5d_vol,\n",
    "               df_WILL5000_30d_vol\n",
    "              ], axis=1)[52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.concat([week, \n",
    "#                week_week, \n",
    "#                month, \n",
    "#                month_month, \n",
    "#                three_m, \n",
    "#                three_three, \n",
    "#                six_m, \n",
    "#                six_six, \n",
    "#                one_y,\n",
    "#               ], axis=1)[52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1w = df_merged.positive_gap.shift(-1)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "y1m = df_merged.positive_gap.shift(-4)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "y3m = df_merged.positive_gap.shift(-13)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "y6m = df_merged.positive_gap.shift(-26)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "y12m = df_merged.positive_gap.shift(-52)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDPC1y1w = df_merged.USREC.shift(-1)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "# y1m = df_merged.USREC.shift(-4)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "# y3m = df_merged.USREC.shift(-13)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "# y6m = df_merged.USREC.shift(-26)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)\n",
    "# y12m = df_merged.USREC.shift(-52)[X.index].fillna(method=\"ffill\").apply(lambda x: 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGS30_1                    0\n",
       "DGS10_1                    0\n",
       "DGS2_1                     0\n",
       "DGS5_1                     0\n",
       "DTB3_1                     0\n",
       "MORTGAGE30US_1             0\n",
       "AAA_1                      0\n",
       "BAA_1                      0\n",
       "FEDFUNDS_1                 0\n",
       "TB3SMFFM_1                 0\n",
       "UMCSENT_1                  0\n",
       "CIVPART_1                  0\n",
       "TCU_1                      0\n",
       "UNRATE_1                   0\n",
       "LNS14000002_1              0\n",
       "NFCI_1                     0\n",
       "2-10_1                     0\n",
       "10-30_1                    0\n",
       "gap_1                      0\n",
       "TERMCBAUTO48NS_1           0\n",
       "TERMCBPER24NS_1            0\n",
       "CEFDFSA066MSFRBPHI_1       0\n",
       "INTDSRUSM193N_1         1299\n",
       "PSAVERT_1                  0\n",
       "DPRIME_1                   0\n",
       "MSACSR_1                   0\n",
       "CSCICP03USM665S_1          0\n",
       "WILL5000INDFC_1            0\n",
       "NIKKEI225_1                0\n",
       "CPIAUCSL_1                 0\n",
       "                        ... \n",
       "CSCICP03USM665S            0\n",
       "DGS30                      0\n",
       "DGS10                      0\n",
       "DGS2                       0\n",
       "DGS5                       0\n",
       "DTB3                       0\n",
       "MORTGAGE30US               0\n",
       "AAA                        0\n",
       "BAA                        0\n",
       "FEDFUNDS                   0\n",
       "TB3SMFFM                   0\n",
       "UMCSENT                    0\n",
       "CIVPART                    0\n",
       "TCU                        0\n",
       "UNRATE                     0\n",
       "LNS14000002                0\n",
       "NFCI                       0\n",
       "2-10                       0\n",
       "10-30                      0\n",
       "gap                        0\n",
       "TERMCBAUTO48NS             0\n",
       "TERMCBPER24NS              0\n",
       "CEFDFSA066MSFRBPHI         0\n",
       "INTDSRUSM193N           1350\n",
       "PSAVERT                    0\n",
       "DPRIME                     0\n",
       "MSACSR                     0\n",
       "CSCICP03USM665S            0\n",
       "WILL5000INDFC              0\n",
       "WILL5000INDFC              0\n",
       "Length: 794, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1563d95f9e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 382\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_.cumsum())\n",
    "plt.title(\"PCA Variance Explained\")\n",
    "plt.xlabel(\"Nth Component\")\n",
    "plt.ylabel(\"Variance Explained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_pca[:int(X_pca.shape[0]*0.7), :n_pc]\n",
    "X_test = X_pca[int(X_pca.shape[0]*0.7):, :n_pc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y1w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1w_train = y1w[:int(X_pca.shape[0]*0.7)]\n",
    "y1w_test = y1w[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=0.1, gamma=0.001, probability=True)\n",
    "clf.fit(X_train, y1w_train)\n",
    "confusion_matrix(clf.predict(X_test), y1w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y1w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y1w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"1-week US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/1w_gap_svc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1m_train = y1m[:int(X_pca.shape[0]*0.7)]\n",
    "y1m_test = y1m[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=20, gamma=0.00001, probability=True)\n",
    "clf.fit(X_train, y1m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y1m_test))\n",
    "print(\"train:\", clf.score(X_train, y1m_train))\n",
    "print(\"test\", clf.score(X_test, y1m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"1-month US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/1m_gap_svc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3m_train = y3m[:int(X_pca.shape[0]*0.7)]\n",
    "y3m_test = y3m[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(C=20, gamma=0.00001, probability=True)\n",
    "clf.fit(X_train, y3m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y3m_test))\n",
    "print(\"train:\", clf.score(X_train, y3m_train))\n",
    "print(\"test\", clf.score(X_test, y3m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"3-month US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/3m_gap_svc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_features=120, \n",
    "                             n_estimators=60, \n",
    "                             max_depth=8, \n",
    "                             min_samples_leaf=100, \n",
    "                             random_state=0,\n",
    "                             class_weight=\"balanced\"\n",
    "                            )\n",
    "clf.fit(X_train, y3m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y3m_test))\n",
    "print(\"train:\", clf.score(X_train, y3m_train))\n",
    "print(\"test\", clf.score(X_test, y3m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"3-month US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/3m_gap_rfc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6m_train = y6m[:int(X_pca.shape[0]*0.7)]\n",
    "y6m_test = y6m[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=35,\n",
    "          gamma=0.00001,\n",
    "          probability=True)\n",
    "clf.fit(X_train, y6m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y6m_test))\n",
    "print(clf.score(X_train, y6m_train))\n",
    "print(clf.score(X_test, y6m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"6-month US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"], loc=4)\n",
    "plt.savefig(\"../images/6m_gap_svc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_features=100, \n",
    "                             n_estimators=30, \n",
    "                             max_depth=8, \n",
    "                             min_samples_leaf=100, \n",
    "                             random_state=0,\n",
    "                             class_weight=\"balanced\"\n",
    "                            )\n",
    "clf.fit(X_train, y6m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y6m_test))\n",
    "print(clf.score(X_train, y6m_train))\n",
    "print(clf.score(X_test, y6m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"6-month Forecast: US Positive Output Gap Probability\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"], loc=4)\n",
    "plt.savefig(\"../images/6m_gap_rfc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y12m_train = y12m[:int(X_pca.shape[0]*0.7)]\n",
    "y12m_test = y12m[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=2, \n",
    "                    learning_rate=0.1, \n",
    "                    n_estimators=200,\n",
    "                    gamma=1,\n",
    "                    random_state=0,\n",
    "                    scale_pos_weight=y6m_train.value_counts()[0]/y6m_train.value_counts()[1],\n",
    "                    reg_alpha=100,\n",
    "                    reg_lambda=100\n",
    "                   )\n",
    "clf.fit(X_train, \n",
    "        y6m_train, \n",
    "        eval_set = [(X_train, y6m_train), (X_test, y6m_test)],\n",
    "        eval_metric=[\"error\", \"logloss\"],\n",
    "        early_stopping_rounds=5,\n",
    "        verbose=False\n",
    "       )\n",
    "print(confusion_matrix(clf.predict(X_test), y6m_test))\n",
    "print(clf.score(X_train, y6m_train))\n",
    "print(clf.score(X_test, y6m_test))\n",
    "\n",
    "# retrieve performance metrics\n",
    "results = clf.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "ax[0].plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax[0].plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Log Loss')\n",
    "ax[0].set_title('XGBoost Log Loss')\n",
    "# plot classification error\n",
    "ax[1].plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax[1].plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('Classification Error')\n",
    "ax[1].set_title('XGBoost Classification Error')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"6-month US Positive Output Gap Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"], loc=4)\n",
    "plt.savefig(\"../images/6m_gap_xgc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc_scores = {}\n",
    "xgc_feature_sets = []\n",
    "k=0\n",
    "for i in range(0, 100, 10):\n",
    "    for j in range(0, 100, 10):\n",
    "        xgc = XGBClassifier(reg_alpha=i, reg_lambda=j)\n",
    "        xgc.fit(X_train,\n",
    "                y6m_train,\n",
    "                eval_set = [(X_train, y6m_train), (X_test, y6m_test)],\n",
    "                eval_metric=[\"error\", \"logloss\"],\n",
    "                early_stopping_rounds=5,\n",
    "                verbose=False)\n",
    "\n",
    "        \n",
    "        xgc_features = pd.DataFrame(xgc.feature_importances_, \n",
    "                                    columns=[\"importance\"]\n",
    "                                   ).sort_values(by=\"importance\",\n",
    "                                                 ascending=False) \n",
    "                                \n",
    "        xgc_scores[k] = [i,\n",
    "                         j,\n",
    "                         clf.evals_result()['validation_0']['logloss'][-1],\n",
    "                         clf.evals_result()['validation_1']['logloss'][-1],\n",
    "                         clf.evals_result()['validation_0']['error'][-1],\n",
    "                         clf.evals_result()['validation_1']['error'][-1],\n",
    "                         np.sum(xgc_features.importance>0)]\n",
    "        xgc_feature_sets.append(xgc_features)\n",
    "        k += 1\n",
    "        if k%10 ==0:\n",
    "            print(\"Progress: {}% completed\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc_reg_score = pd.DataFrame(xgc_scores, \n",
    "                             index=[\"alpha\",\n",
    "                                    \"lambda\",\n",
    "                                    \"train_log_loss\",\n",
    "                                    \"test_log_loss\",\n",
    "                                    \"train_error\",\n",
    "                                    \"test_error\",\n",
    "                                    \"n_features\"\n",
    "                                   ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(xgc_reg_score.n_features, \n",
    "            xgc_reg_score.train_log_loss,\n",
    "            s=10\n",
    "           )\n",
    "plt.scatter(xgc_reg_score.n_features,\n",
    "            xgc_reg_score.test_log_loss,\n",
    "            s=10\n",
    "           )\n",
    "plt.title(\"XGBoost Classifier No of Features and Scores\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/output_gap_xgc_reg_log_loss_6m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xgc_reg_score.n_features, \n",
    "            xgc_reg_score.train_error,\n",
    "            s=10\n",
    "           )\n",
    "plt.scatter(xgc_reg_score.n_features,\n",
    "            xgc_reg_score.test_error,\n",
    "            s=10\n",
    "           )\n",
    "plt.title(\"XGBoost Classifier No of Features and Scores\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/output_gap_xgc_reg_error_6m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y12m_train = y12m[:int(X_pca.shape[0]*0.7)]\n",
    "y12m_test = y12m[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=100, \n",
    "          gamma=0.000005, \n",
    "          probability=True,\n",
    "          random_state=0,\n",
    "          class_weight=\"balanced\"\n",
    "         )\n",
    "clf.fit(X_train, y12m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y12m_test))\n",
    "print(\"train:\", clf.score(X_train, y12m_train))\n",
    "print(\"test:\", clf.score(X_test, y12m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"12-month US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/12m_gap_svc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y12m_train.value_counts()[1]/y12m_train.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_features=100, \n",
    "                             n_estimators=70, \n",
    "                             max_depth=30, \n",
    "                             min_samples_leaf=50,\n",
    "                             random_state=0, \n",
    "                             class_weight=\"balanced\"\n",
    "                            )\n",
    "clf.fit(X_train, \n",
    "        y12m_train)\n",
    "print(confusion_matrix(clf.predict(X_test), y12m_test))\n",
    "print(\"train:\", clf.score(X_train, y12m_train))\n",
    "print(\"test:\", clf.score(X_test, y12m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"12-month Forecast: US Positive Output Gap Probability\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"], loc=4)\n",
    "plt.savefig(\"../images/12m_gap_rfc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=2, \n",
    "                    learning_rate=0.01, \n",
    "                    n_estimators=200,\n",
    "                    gamma=1,\n",
    "                    scale_pos_weight=y6m_train.value_counts()[0]/y6m_train.value_counts()[1]\n",
    "                   )\n",
    "clf.fit(X_train, \n",
    "        y12m_train, \n",
    "        eval_set = [(X_train, y12m_train), (X_test, y12m_test)],\n",
    "        eval_metric=[\"error\", \"logloss\"],\n",
    "        early_stopping_rounds=5,\n",
    "        verbose=False\n",
    "       )\n",
    "print(confusion_matrix(clf.predict(X_test), y12m_test))\n",
    "print(\"train:\", clf.score(X_train, y12m_train))\n",
    "print(\"test:\", clf.score(X_test, y12m_test))\n",
    "\n",
    "# retrieve performance metrics\n",
    "results = clf.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,3))\n",
    "ax[0].plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax[0].plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Log Loss')\n",
    "ax[0].set_title('XGBoost Log Loss')\n",
    "# plot classification error\n",
    "ax[1].plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax[1].plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('Classification Error')\n",
    "ax[1].set_title('XGBoost Classification Error')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(clf.predict_proba(X_pca[:, :n_pc])[:, 1])\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.positive_gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"12-month US Recession Forecast\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend([\"Positive Output Gap\", \"Prediction\"], loc=4)\n",
    "plt.savefig(\"../images/12m_gap_xgc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc_scores = {}\n",
    "xgc_feature_sets = []\n",
    "k=0\n",
    "for i in range(0, 100, 10):\n",
    "    for j in range(0, 100, 10):\n",
    "        xgc = XGBClassifier(reg_alpha=i, reg_lambda=j)\n",
    "        xgc.fit(X_train, y12m_train)\n",
    "\n",
    "        \n",
    "        xgc_features = pd.DataFrame(xgc.feature_importances_, \n",
    "                                    columns=[\"importance\"]\n",
    "                                   ).sort_values(by=\"importance\",\n",
    "                                                 ascending=False) \n",
    "                                \n",
    "        xgc_scores[k] = [i,\n",
    "                         j,\n",
    "                         xgc.score(X_train, y12m_train),\n",
    "                         xgc.score(X_test, y12m_test),\n",
    "                         np.sum(xgc_features.importance>0)]\n",
    "        xgc_feature_sets.append(xgc_features)\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc_reg_score = pd.DataFrame(xgc_scores, \n",
    "                             index=[\"alpha\",\n",
    "                                    \"lambda\",\n",
    "                                    \"train\",\n",
    "                                    \"test\",\n",
    "                                    \"n_features\"\n",
    "                                   ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(xgc_reg_score.n_features, \n",
    "            xgc_reg_score.train,\n",
    "            s=10\n",
    "           )\n",
    "plt.scatter(xgc_reg_score.n_features,\n",
    "            xgc_reg_score.test,\n",
    "            s=10\n",
    "           )\n",
    "plt.title(\"XGBoost Classifier No of Features and Scores\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/output_gap_xgc_reg_score_12m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [\"DGS30\",\n",
    "          \"DGS10\",\n",
    "          \"DGS2\",\n",
    "          \"DGS5\",\n",
    "          \"DTB3\",\n",
    "          \"MORTGAGE30US\",\n",
    "          \"AAA\",\n",
    "          \"BAA\",\n",
    "          \"FEDFUNDS\",\n",
    "          \"TB3SMFFM\",\n",
    "          \"UMCSENT\",  \n",
    "          \"CIVPART\",\n",
    "          \"TCU\",\n",
    "          \"UNRATE\",\n",
    "          \"LNS14000002\",\n",
    "          \"NFCI\",\n",
    "          \"2-10\",\n",
    "          \"10-30\",\n",
    "#           \"gap\",\n",
    "          \"TERMCBAUTO48NS\",\n",
    "          \"TERMCBPER24NS\",\n",
    "          \"CEFDFSA066MSFRBPHI\",\n",
    "          \"INTDSRUSM193N\",\n",
    "          \"PSAVERT\",\n",
    "          \"DPRIME\",\n",
    "          \"MSACSR\",\n",
    "          \"CSCICP03USM665S\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week = change(df_merged, percent, actual, 1)\n",
    "week_week = week.diff(1).add_suffix(\"_1\")\n",
    "month = change(df_merged, percent, actual, 4)\n",
    "month_month = month.diff(4).add_suffix(\"_4\")\n",
    "three_m = change(df_merged, percent, actual, 13)\n",
    "three_three = three_m.diff(13).add_suffix(\"_13\")\n",
    "six_m = change(df_merged, percent, actual, 26)\n",
    "six_six = six_m.diff(26).add_suffix(\"_26\")\n",
    "one_y = change(df_merged, percent, actual, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([week, \n",
    "               week_week, \n",
    "               month, \n",
    "               month_month, \n",
    "               three_m, \n",
    "               three_three, \n",
    "               six_m, \n",
    "               six_six, \n",
    "               one_y,\n",
    "               df_merged[actual].fillna(method=\"ffill\"),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(1),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(4),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(13),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(26),\n",
    "               df_merged[actual].fillna(method=\"ffill\").shift(52),\n",
    "               df_WILL5000_5d_vol,\n",
    "               df_WILL5000_30d_vol\n",
    "              ], axis=1)[52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gap = pd.concat([df_merged.gap,\n",
    "#                    pd.DataFrame(df_merged.gap.diff(1)).add_suffix(\"_diff\"),\n",
    "#                    pd.DataFrame(df_merged.gap.diff(1).diff(1)).add_suffix(\"_diff_diff\")\n",
    "                  ], axis=1)[52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_gap = np.concatenate([np.array(X_gap), X_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_gap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_gap = X_pca_gap[:int(X_pca.shape[0]*0.7), :n_pc]\n",
    "X_test_gap = X_pca_gap[int(X_pca.shape[0]*0.7):, :n_pc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1w = df_merged.gap.shift(-1)[X.index].fillna(method=\"ffill\")\n",
    "g1m = df_merged.gap.shift(-4)[X.index].fillna(method=\"ffill\")\n",
    "g3m = df_merged.gap.shift(-13)[X.index].fillna(method=\"ffill\")\n",
    "g6m = df_merged.gap.shift(-26)[X.index].fillna(method=\"ffill\")\n",
    "g12m = df_merged.gap.shift(-52)[X.index].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g6m_train = g6m[:int(X_pca.shape[0]*0.7)]\n",
    "g6m_test = g6m[int(X_pca.shape[0]*0.7):]\n",
    "g12m_train = g12m[:int(X_pca.shape[0]*0.7)]\n",
    "g12m_test = g12m[int(X_pca.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# i = 1\n",
    "# score_dict = {}\n",
    "# for train_index, test_index in tscv.split(X_train):\n",
    "#     X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "#     y_tr, y_tst = g12m_train[train_index], g12m_train[test_index]\n",
    "#     score = 0\n",
    "#     for c in [np.logspace(-10, 10, 2)]:\n",
    "#         for e in [np.logspace(-20, 0, 2)]:\n",
    "#             svm = SVR(C=c, epsilon=e, gamma=\"auto\")\n",
    "#             svm.fit(X_tr, y_tr)\n",
    "#             if score < svm.score(X_tst, y_tst):\n",
    "#                 score_dict[i] = [c, e, svm.score(X_tst, y_tst)]\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm = SVR(C=50, \n",
    "          epsilon=10**-7, \n",
    "          gamma=\"auto\")\n",
    "svm.fit(X_train_gap, g6m_train)\n",
    "print(\"train\", svm.score(X_train_gap, g6m_train))\n",
    "print(\"test\", svm.score(X_test_gap, g6m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(svm.predict((X_pca_gap[:, :n_pc])))\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"6-month US Output Gap Forecast\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.legend([\"Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/6m_gap_svm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# i = 1\n",
    "# score_dict = {}\n",
    "# for train_index, test_index in tscv.split(X_train):\n",
    "#     X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "#     y_tr, y_tst = g12m_train[train_index], g12m_train[test_index]\n",
    "#     score = 0\n",
    "#     for mf in np.linspace(10, 100, 10):\n",
    "#         for ne in np.linspace(10, 30, 11):\n",
    "#             for md in np.linspace(5, 25, 11):\n",
    "#                 for msl in np.linspace(10, 40, 16):\n",
    "#                     rfr = RandomForestRegressor(max_features=int(mf),\n",
    "#                                                 n_estimators=int(ne), \n",
    "#                                                 max_depth=int(md),\n",
    "#                                                 min_samples_leaf=int(msl)\n",
    "#                                                )\n",
    "#                     rfr.fit(X_tr, y_tr)\n",
    "#                     if score < rfr.score(X_tst, y_tst):\n",
    "#                         score_dict[i] = [mf, ne, md, msl, rfr.score(X_tst, y_tst)]\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_features=50,\n",
    "                            n_estimators=50, \n",
    "                            max_depth=20, \n",
    "                            min_samples_leaf=30,\n",
    "                            random_state=0\n",
    "                           )\n",
    "rfr.fit(X_train_gap, g6m_train)\n",
    "print(\"train: \", rfr.score(X_train_gap, g6m_train))\n",
    "print(\"test: \", rfr.score(X_test_gap, g6m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(rfr.predict((X_pca_gap[:, :n_pc])))\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"6-month US Output Gap Forecast\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.legend([\"Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/6m_gap_rfr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgr = XGBRegressor(max_depth=3, \n",
    "                   min_child_weight=20,\n",
    "                   gamma=0,\n",
    "                   subsample=0.95,\n",
    "                   colsample_bytree=1,\n",
    "                   learning_rate=0.3, \n",
    "                   n_estimators=200,\n",
    "                   reg_alpha=0.001,\n",
    "                   random_state=0\n",
    "                  )\n",
    "xgr.fit(X_train_gap,\n",
    "        g6m_train,\n",
    "        eval_set=[(X_train_gap, g6m_train), (X_test_gap, g6m_test)],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose=False)\n",
    "print(\"train\", xgr.score(X_train_gap, g6m_train))\n",
    "print(\"test\", xgr.score(X_test_gap, g6m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(xgr.predict((X_pca_gap[:, :n_pc])))\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"6-month US Output Gap Forecast\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.legend([\"Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/6m_gap_xgr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(xgr, height=0.9, max_num_features=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm = SVR(C=50, \n",
    "          epsilon=10**-7, \n",
    "          gamma=\"auto\")\n",
    "svm.fit(X_train_gap, g12m_train)\n",
    "print(\"train\", svm.score(X_train_gap, g12m_train))\n",
    "print(\"test\", svm.score(X_test_gap, g12m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(svm.predict((X_pca_gap[:, :n_pc])))\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"12-month US Output Gap Forecast\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.legend([\"Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/12m_gap_svm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# i = 1\n",
    "# score_dict = {}\n",
    "# for train_index, test_index in tscv.split(X_train):\n",
    "#     X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "#     y_tr, y_tst = g12m_train[train_index], g12m_train[test_index]\n",
    "#     score = 0\n",
    "#     for mf in np.linspace(10, 100, 10):\n",
    "#         for ne in np.linspace(10, 30, 11):\n",
    "#             for md in np.linspace(5, 25, 11):\n",
    "#                 for msl in np.linspace(10, 40, 16):\n",
    "#                     rfr = RandomForestRegressor(max_features=int(mf),\n",
    "#                                                 n_estimators=int(ne), \n",
    "#                                                 max_depth=int(md),\n",
    "#                                                 min_samples_leaf=int(msl)\n",
    "#                                                )\n",
    "#                     rfr.fit(X_tr, y_tr)\n",
    "#                     if score < rfr.score(X_tst, y_tst):\n",
    "#                         score_dict[i] = [mf, ne, md, msl, rfr.score(X_tst, y_tst)]\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_features=50,\n",
    "                            n_estimators=50, \n",
    "                            max_depth=20, \n",
    "                            min_samples_leaf=30,\n",
    "                            random_state=0\n",
    "                           )\n",
    "rfr.fit(X_train_gap, g12m_train)\n",
    "print(\"train: \", rfr.score(X_train_gap, g12m_train))\n",
    "print(\"test: \", rfr.score(X_test_gap, g12m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(rfr.predict((X_pca_gap[:, :n_pc])))\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"12-month US Output Gap Forecast\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.legend([\"Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/12m_gap_rfr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgr = XGBRegressor(max_depth=2, \n",
    "                   learning_rate=0.13, \n",
    "                   n_estimators=40)\n",
    "xgr.fit(X_train_gap,\n",
    "        g12m_train)\n",
    "print(\"train\", xgr.score(X_train_gap, g12m_train))\n",
    "print(\"test\", xgr.score(X_test_gap, g12m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(xgr.predict((X_pca_gap[:, :n_pc])))\n",
    "pred.set_index(X.index, inplace=True)\n",
    "pred.columns = [\"pred\"]\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = plt.plot(pd.merge(df_merged.gap[X_scaled.index], pred, on=\"date\"))\n",
    "plt.title(\"12-month US Output Gap Forecast\")\n",
    "plt.ylabel(\"GDP\")\n",
    "plt.legend([\"Output Gap\", \"Prediction\"])\n",
    "plt.savefig(\"../images/12m_gap_xgr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
